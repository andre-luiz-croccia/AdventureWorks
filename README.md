# ğŸš€ Projeto Adventure Works - Databricks + Terraform + Docker

## ğŸ“¦ Estrutura do Projeto

- **terraform/**: Scripts Terraform para provisionamento e upload dos notebooks no Databricks.
- **raw_api_extraction.py**: Notebook Python para extraÃ§Ã£o de dados de uma API.
- **raw_mysql_extraction.py**: Notebook Python para extraÃ§Ã£o de dados de um banco MySQL.
- **.env**: Arquivo com variÃ¡veis sensÃ­veis (nÃ£o versionado).
- **Dockerfile / docker-compose.yml**: ContainerizaÃ§Ã£o para execuÃ§Ã£o padronizada.
- **set_env.sh**: Script que exporta as variÃ¡veis do `.env` no formato que o Terraform reconhece.

---

## ğŸ”„ Fluxo do Projeto

```mermaid
flowchart TD
    A[Preencher .env] --> B[Executar Docker Compose]
    B --> C[Entrar no container com bash]
    C --> D[Rodar set_env.sh]
    D --> E[Terraform init e apply]
    E --> F[Upload dos notebooks no Databricks]
    F --> G[Executar os Notebooks no Databricks]
```

---

## âš™ï¸ Tecnologias Utilizadas

- ğŸ³ Docker + Docker Compose
- ğŸ—ï¸ Terraform v1.8
- ğŸ”— Databricks CLI
- â˜ï¸ Databricks Provider Terraform

---

## ğŸ—‚ï¸ Estrutura de DiretÃ³rios

```
Adventure-Works/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ set_env.sh
â”‚   â”œâ”€â”€ .env.exemplo
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ raw_api_extraction.py
â”‚       â””â”€â”€ raw_mysql_extraction.py
```

---

## ğŸ”‘ ConfiguraÃ§Ã£o do Ambiente

1. Crie um arquivo `.env` com base no `.env.exemplo`:

```env
DATABRICKS_HOST=https://<seu-workspace>.cloud.databricks.com
DATABRICKS_TOKEN=<seu_token>
USER_EMAIL=<seu_email@databricks.com>
```

---

## ğŸš€ Como Executar

### 1ï¸âƒ£ Build do Container

```bash
docker-compose build
```

### 2ï¸âƒ£ Acessar o Container com Bash

> âš ï¸ Importante: use `--entrypoint /bin/bash`, pois o container nÃ£o possui um processo principal rodando.

```bash
docker-compose run --entrypoint /bin/bash terraform-databricks
```

### 3ï¸âƒ£ Inicializar o Terraform

```bash
terraform init
```

### 4ï¸âƒ£ Carregar VariÃ¡veis e Aplicar

```bash
bash set_env.sh
terraform apply
```

---

## ğŸ§¹ Limpeza (opcional)

Para remover containers Ã³rfÃ£os e a rede:

```bash
docker-compose down --remove-orphans
```

---

## ğŸ“„ ExplicaÃ§Ã£o dos Notebooks

### ğŸ”— `raw_api_extraction.py`

- Faz requisiÃ§Ãµes HTTP a uma API.
- Processa os dados (JSON â†’ DataFrame).
- Salva no ambiente Databricks no catalog: `ted_dev.<nome_da_tabela>`.

### ğŸ—„ï¸ `raw_mysql_extraction.py`

- Conecta ao MySQL.
- Executa consultas e extrai dados.
- Salva no Databricks no catalog: `ted_dev.<nome_da_tabela>`.

> âœ… Os notebooks `.ipynb` gerados sÃ£o espelhos da execuÃ§Ã£o dentro do Databricks, para referÃªncia local.

---

## ğŸ” Gerenciamento de Segredos no Databricks

### âœ… CriaÃ§Ã£o de Secret Scope

```bash
databricks secrets create-scope --scope sqlserver_scope
```

### ğŸ”‘ Chaves armazenadas no scope `sqlserver_scope`:

- **Banco de Dados:**
  - `sql_host`
  - `sql_port`
  - `sql_user`
  - `sql_password`

- **API:**
  - `api_user`
  - `api_pass`

### ğŸ” Acesso nos notebooks:

```python
dbutils.secrets.get(scope="sqlserver_scope", key="sql_host")
dbutils.secrets.get(scope="sqlserver_scope", key="api_user")
```

---

## âœ… Recursos Provisionados

- DiretÃ³rio no Databricks: `/Users/<seu_email>/Adventure_Works`
- Notebooks enviados automaticamente:
  - `raw_api_extraction`
  - `raw_mysql_extraction`

> ApÃ³s provisionar, execute os notebooks diretamente no Databricks.

---

## âš ï¸ ObservaÃ§Ãµes

- O arquivo `.env` **nÃ£o deve ser versionado**.
- O uso de Docker garante portabilidade e reprodutibilidade do ambiente.
- A utilizaÃ§Ã£o do comando:

```bash
docker-compose run --entrypoint /bin/bash terraform-databricks
```

Ã© **obrigatÃ³ria**, pois o container nÃ£o possui um processo ativo por padrÃ£o.